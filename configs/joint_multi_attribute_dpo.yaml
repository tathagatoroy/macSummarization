#global constants for all zero shot experiments
global:
  train_dataset_path : /home2/tathagato/summarization/MACSUM/dataset/macdoc/train.json
  val_dataset_path : /home2/tathagato/summarization/MACSUM/dataset/macdoc/val.json
  test_dataset_path : /home2/tathagato/summarization/MACSUM/dataset/macdoc/test_dataset.json
  load_in_4bit : True 
  bnb_4bit_quant_type : "nf4"
  bnb_4bit_compute_dtype : "bfloat16"
  bnb_4bit_use_double_quant : False
  device : "cuda:0"
  rank : 32
  lora_alpha : 16
  lora_dropout : 0.1
  target_modules : ['k_proj', 'v_proj', 'q_proj', 'up_proj', 'down_proj', 'gate_proj']
  top_p : 0.95
  top_k : 50
  max_new_tokens : 500
  num_return_sequences : 1
  do_sample : True
  output_dir : /scratch/tathagato/naacl/joint_mult_attribute_dpo
  max_seq_len : 2048
  batch_size : 8
  learning_rate : 0.000005
  gradient_accumulation_steps : 8
  num_epochs : 2
  warmup_ratio : 0.1
  max_grad_norm : 1.0
  logging_steps : 10
  eval_interval : 100
  max_lr : 0.000005
  min_lr : 0.000001
  do_wandb : True
  wandb_project : "naacl"
  optim : "adamw_torch_fused"
  lr_scheduler_type : "cosine"
  ddp_find_unused_parameters : False
  max_prompt_length : 1900
experiments :
  llama_length_and_extractiveness_test:
    model_id : akjindal53244/Llama-3.1-Storm-8B
    attributes : ['length', 'extractiveness']
    model_type : llama

  llama_length_and_extractiveness:
    model_id : akjindal53244/Llama-3.1-Storm-8B
    attributes : ['length', 'extractiveness']
    model_type : llama

  llama_length_and_topic:
    model_id : akjindal53244/Llama-3.1-Storm-8B
    attributes : ['length', 'topic']
    model_type : llama
  
  llama_length_and_specificity:
    model_id : akjindal53244/Llama-3.1-Storm-8B
    attributes : ['length', 'specificity']
    model_type : llama
  
  llama_extractiveness_and_topic:
    model_id : akjindal53244/Llama-3.1-Storm-8B
    attributes : ['extractiveness', 'topic']
    model_type : llama
  
  llama_extractiveness_and_specificity:
    model_id : akjindal53244/Llama-3.1-Storm-8B
    attributes : ['extractiveness', 'specificity']
    model_type : llama
  
  llama_topic_and_specificity:
    model_id : akjindal53244/Llama-3.1-Storm-8B
    attributes : ['topic', 'specificity']
    model_type : llama
  
  mistral_length_and_extractiveness:
    model_id : mistralai/Mistral-7B-Instruct-v0.3
    attributes : ['length', 'extractiveness']
    model_type : mistral
  
  mistral_length_and_topic:
    model_id : mistralai/Mistral-7B-Instruct-v0.3
    attributes : ['length', 'topic']
    model_type : mistral
  
  mistral_length_and_specificity:
    model_id : mistralai/Mistral-7B-Instruct-v0.3
    attributes : ['length', 'specificity']
    model_type : mistral
  
  mistral_extractiveness_and_topic:
    model_id : mistralai/Mistral-7B-Instruct-v0.3
    attributes : ['extractiveness', 'topic']
    model_type : mistral
  
  mistral_extractiveness_and_specificity:
    model_id : mistralai/Mistral-7B-Instruct-v0.3
    attributes : ['extractiveness', 'specificity']
    model_type : mistral
  
  mistral_topic_and_specificity:
    model_id : mistralai/Mistral-7B-Instruct-v0.3
    attributes : ['topic', 'specificity']
    model_type : mistral



  




